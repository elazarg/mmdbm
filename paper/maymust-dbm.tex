\documentclass[11pt]{article}

\usepackage{amsmath,amssymb,amsthm}
\usepackage{algorithm}
\usepackage{algpseudocode}
\usepackage{booktabs}
\usepackage{hyperref}
\usepackage{cleveref}
\usepackage[margin=1in]{geometry}

% Theorem environments
\newtheorem{theorem}{Theorem}[section]
\newtheorem{lemma}[theorem]{Lemma}
\newtheorem{proposition}[theorem]{Proposition}
\newtheorem{corollary}[theorem]{Corollary}
\newtheorem{definition}[theorem]{Definition}
\newtheorem{example}[theorem]{Example}
\newtheorem{remark}[theorem]{Remark}

% Notation
\newcommand{\R}{\mathbb{R}}
\newcommand{\Z}{\mathbb{Z}}
\newcommand{\Rinf}{\R \cup \{-\infty, +\infty\}}
\newcommand{\upper}{\overline}
\newcommand{\lower}{\underline}
\newcommand{\meet}{\sqcap}
\newcommand{\join}{\sqcup}
\newcommand{\order}{\sqsubseteq}
\newcommand{\conc}{\gamma}
\newcommand{\abs}{\alpha}

\title{The May-Must Difference-Bound Matrix Domain:\\
A Polarity-Aware Relational Numerical Domain}

\author{Technical Report}
\date{}

\begin{document}

\maketitle

\begin{abstract}
We present the \emph{May-Must Difference-Bound Matrix} (May-Must DBM) domain,
a polarity-aware numerical abstract domain for verification problems where
different variables require tracking different \emph{directions} of bounds.
The domain is a standard over-approximation (concretization is a set of
valuations), but partitions variables into two classes: \emph{may}-variables
where we track upper bounds on possible values, and \emph{must}-variables
where we track lower bounds on guaranteed values. This design prevents a
common encoding pitfall where scalar summaries of interval properties lose
precision across joins. We provide definitions, soundness arguments,
and worked examples motivated by memory region tracking in program verifiers.
\end{abstract}

\tableofcontents
\newpage

%==============================================================================
\section{Introduction and Motivation}
\label{sec:intro}
%==============================================================================

\subsection{The Core Problem: Tracking Guarantees Across Joins}

Many program analyses need to track \emph{guaranteed properties} that must
hold in all executions, not just \emph{possible values} that might occur.
Standard abstract domains use over-approximation: they track sets of possible
values, and join computes a superset. But when we need \emph{intersection}
semantics---what is \emph{definitely} true after either branch---standard
over-approximation requires indirect encodings.

\subsection{Motivating Example: Accessible Memory Regions}

Consider tracking memory regions with a certain property (e.g., containing
numeric values rather than pointers). A pointer $p$ points into a buffer,
and we track the interval around $p$ where the property holds.

\begin{center}
\begin{tabular}{ll}
\textbf{Branch 1:} & write numbers to $p$ and $p+1$ $\Rightarrow$ accessible offsets: $[0, +1]$ \\
\textbf{Branch 2:} & write numbers to $p$ and $p-1$ $\Rightarrow$ accessible offsets: $[-1, 0]$
\end{tabular}
\end{center}

After joining, what offsets are \emph{guaranteed} accessible? The answer is
the \textbf{intersection}: $[0, +1] \cap [-1, 0] = [0, 0]$. Only offset 0 (the
position $p$ itself) is guaranteed accessible in both branches.

\subsection{A Common Encoding Pitfall}

\textbf{Attempt 1: Track ``size'' as a single variable.}
\begin{itemize}
    \item Branch 1: $\mathit{size} = 2$ (covers 2 positions)
    \item Branch 2: $\mathit{size} = 2$ (covers 2 positions)
    \item Join: $\mathit{size} = 2$ \quad \textbf{WRONG!} Guaranteed size is 1.
\end{itemize}
The problem: a single size variable cannot capture that the intervals have
the same size but \emph{different positions}. After join, only their
intersection is guaranteed.

\textbf{Attempt 2: Track lower and upper bounds as two variables.}

You could track $\mathit{lb}$ (lower bound) and $\mathit{ub}$ (upper bound)
separately. Standard DBM/intervals will correctly compute the intersection
at joins. This works, but:
\begin{itemize}
    \item It's an indirect encoding: you wanted to track ``guaranteed reach,''
    but you're encoding it as an interval that happens to compute correctly
    \item If you later derive a scalar summary (e.g., ``size''), you need a
    bespoke transformer for that derived quantity
    \item Standard over-approximation tracks \emph{both} upper and lower bounds
    on each variable, even when only one direction matters
\end{itemize}

\subsection{Our Solution: Polarity-Aware Constraints}

We observe that the quantities being tracked have different \emph{polarities}:
\begin{itemize}
    \item \textbf{May-quantities} (possible values): After join, take the
    \emph{loosest} bound. Upper bounds grow ($\max$), lower bounds shrink ($\min$).

    \item \textbf{Must-quantities} (guaranteed properties): After join, take
    the \emph{weakest} guarantee. For a ``guaranteed reach,'' this means $\min$.
\end{itemize}

For the accessible region example, define:
\begin{itemize}
    \item $\mathit{left\_reach}$: guaranteed reach to the left (must-quantity)
    \item $\mathit{right\_reach}$: guaranteed reach to the right (must-quantity)
\end{itemize}

\begin{center}
\begin{tabular}{lccc}
& Branch 1 & Branch 2 & Join ($\min$) \\
\midrule
$\mathit{left\_reach} \geq$ & 0 & 1 & 0 \\
$\mathit{right\_reach} \geq$ & 1 & 0 & 0 \\
\end{tabular}
\end{center}

By tracking ``guaranteed reach'' (lower bounds) directly as must-quantities,
the join operation ($\min$) automatically computes the intersection of guarantees.

\subsection{Application: Array Bounds Checking}

The same principle applies to array bounds verification:
\[
0 \leq \mathit{index} < \mathit{size}
\]
\begin{itemize}
    \item $\mathit{index}$: a may-quantity (what values \emph{could} the index have?)
    \item $\mathit{size}$: we care about its \emph{guaranteed minimum} (a must-quantity)
\end{itemize}

If $\upper{(\mathit{index})} < \lower{(\mathit{size})}$, the access is safe.
Standard over-approximation \emph{can} handle simple cases here, but the
may-must framing makes the semantics explicit and enables systematic
propagation of constraints between the two classes.

\subsection{Our Contribution}

We define the \emph{May-Must DBM} domain, a polarity-aware extension of
difference-bound matrices that:
\begin{enumerate}
    \item Partitions variables into \textbf{E} (may: track upper bounds) and
    \textbf{A} (must: track guaranteed lower bounds)
    \item Uses \textbf{interval constraints} on cross-class differences ($e - a$),
    enabling bidirectional propagation
    \item Provides \textbf{correct join semantics}: $\max$ on may-bounds,
    $\min$ on must-bounds
    \item Remains a standard over-approximation domain (concretization is a set
    of valuations, ordering by inclusion) while directly tracking the quantities
    that matter for verification
\end{enumerate}

%==============================================================================
\section{Preliminaries}
\label{sec:prelim}
%==============================================================================

\subsection{Notation}

Let $\Rinf = \R \cup \{-\infty, +\infty\}$ denote the extended reals with the
usual arithmetic conventions: $x + (+\infty) = +\infty$ for $x \neq -\infty$,
$x + (-\infty) = -\infty$ for $x \neq +\infty$, and $\min/\max$ extend naturally.
Undefined forms such as $(+\infty) + (-\infty)$ or $(+\infty) - (+\infty)$ may
arise in closure rule candidates; we treat any such candidate as providing no
improvement (i.e., skip it). In floating-point implementations, this corresponds
to ignoring NaN results.

For a constraint $x - y \leq c$, we call $c$ an \emph{upper bound} on the
difference $x - y$. For a constraint $x - y \geq c$, we call $c$ a
\emph{lower bound} on the difference $x - y$.

\subsection{Standard DBM (Review)}

A \emph{Difference-Bound Matrix} (DBM) over variables $\{x_0, x_1, \ldots, x_n\}$
is an $(n+1) \times (n+1)$ matrix $M$ where $M[i,j]$ represents an upper bound
on $x_i - x_j$:
\[
M[i,j] = c \quad \Longleftrightarrow \quad x_i - x_j \leq c
\]

The variable $x_0$ is conventionally fixed to 0, allowing unary constraints:
\begin{itemize}
    \item $M[i, 0] = c$ means $x_i - 0 \leq c$, i.e., $x_i \leq c$
    \item $M[0, i] = c$ means $0 - x_i \leq c$, i.e., $x_i \geq -c$
\end{itemize}

\textbf{Closure:} A DBM is \emph{closed} if $M[i,j] \leq M[i,k] + M[k,j]$ for all
$i,j,k$. The closure is computed by Floyd-Warshall (min-plus semiring).

\textbf{Concretization:} The set of concrete valuations satisfying a DBM $M$ is:
\[
\conc(M) = \{ \rho : \{x_1, \ldots, x_n\} \to \R \mid
\forall i,j.\; \rho(x_i) - \rho(x_j) \leq M[i,j] \}
\]
where $\rho(x_0) = 0$.

%==============================================================================
\section{The May-Must DBM Domain}
\label{sec:domain}
%==============================================================================

\subsection{Variable Classes}

We partition program variables into two disjoint classes based on which
\emph{direction} of bound matters for the analysis:
\begin{itemize}
    \item $E = \{e_1, \ldots, e_{n_E}\}$: \textbf{May}-variables, where we
    track \emph{upper bounds} (what values could they have?)
    \item $A = \{a_1, \ldots, a_{n_A}\}$: \textbf{Must}-variables, where we
    track \emph{lower bounds} (what values are guaranteed?)
\end{itemize}

Additionally, we introduce distinguished zero variables $e_0 = 0$ and $a_0 = 0$
for representing unary constraints.

\begin{remark}[Terminology]
We use ``may'' and ``must'' to indicate the \emph{polarity} of the bounds we
track, not to claim this is an under-approximation domain in the abstract
interpretation sense. The domain remains a standard over-approximation:
$\gamma(S)$ is a set of valuations, and ordering is by subset inclusion.
The distinction is that E-variables contribute upper-bound constraints while
A-variables contribute lower-bound constraints.
\end{remark}

\begin{remark}[Classification Heuristics]
The classification is chosen by the analysis designer based on intended use:
\begin{itemize}
    \item Variables whose \emph{upper} bounds matter (indices, offsets, loop counters) go in $E$
    \item Variables whose \emph{guaranteed lower} bounds matter (sizes, capacities, reaches) go in $A$
\end{itemize}
\end{remark}

\subsection{Abstract State}

\begin{definition}[May-Must DBM State]
\label{def:state}
An abstract state $S = (EE, AA, M^+, M^-)$ consists of four matrices:

\begin{enumerate}
    \item $EE \in \Rinf^{(n_E+1) \times (n_E+1)}$:
    Upper bounds on E-E differences
    \[
    EE[i,j] = \upper{(e_i - e_j)} \quad \text{(over-approximation)}
    \]

    \item $AA \in \Rinf^{(n_A+1) \times (n_A+1)}$:
    Lower bounds on A-A differences
    \[
    AA[i,j] = \lower{(a_i - a_j)} \quad \text{(guaranteed bound)}
    \]

    \item $M^+ \in \Rinf^{n_E \times n_A}$:
    Upper bounds on E-A differences (Mixed upper)
    \[
    M^+[i,j] = \upper{(e_{i+1} - a_{j+1})}
    \]

    \item $M^- \in \Rinf^{n_E \times n_A}$:
    Lower bounds on E-A differences (Mixed lower)
    \[
    M^-[i,j] = \lower{(e_{i+1} - a_{j+1})}
    \]
\end{enumerate}
\end{definition}

\begin{remark}[Index Convention]
$EE$ and $AA$ are $(n+1) \times (n+1)$ matrices with index 0 representing the
constant zero. $M^+$ and $M^-$ are $n_E \times n_A$ matrices with 0-based indexing
that correspond to 1-based variable indices.
\end{remark}

\begin{remark}[Why Intervals on E-A?]
The key insight is that we need \emph{both} upper and lower bounds on $e - a$
differences to enable bidirectional propagation. Given only $\upper{(e-a)}$, we
cannot derive $\upper{(a-e)} = -\lower{(e-a)}$.
\end{remark}

\subsection{Derived Quantities}

From the mixed constraints, we can derive bounds on $a_j - e_i$ (note the
reversed order from how we store constraints):
\begin{align}
\upper{(a_j - e_i)} &= -M^-[i-1, j-1]
    & &\text{since } M^-[i{-}1,j{-}1] = \lower{(e_i - a_j)} \label{eq:ae-upper}\\
\lower{(a_j - e_i)} &= -M^+[i-1, j-1]
    & &\text{since } M^+[i{-}1,j{-}1] = \upper{(e_i - a_j)} \label{eq:ae-lower}
\end{align}

Unary bounds are extracted as:
\begin{align}
\upper{(e_i)} &= EE[i, 0] & \lower{(e_i)} &= -EE[0, i] \\
\lower{(a_j)} &= AA[j, 0] & \upper{(a_j)} &= -AA[0, j]
\end{align}

%==============================================================================
\section{Concretization}
\label{sec:gamma}
%==============================================================================

\begin{definition}[Concretization]
\label{def:gamma}
The concretization of a state $S = (EE, AA, M^+, M^-)$ is the set of all
concrete valuations $\rho : (E \cup A) \to \R$ satisfying all constraints:
\begin{align*}
\conc(S) = \{ \rho \mid
&\forall i,j \in [0, n_E].\; \rho(e_i) - \rho(e_j) \leq EE[i,j] \\
\land\; &\forall i,j \in [0, n_A].\; \rho(a_i) - \rho(a_j) \geq AA[i,j] \\
\land\; &\forall i \in [1, n_E], j \in [1, n_A].\;
M^-[i{-}1, j{-}1] \leq \rho(e_i) - \rho(a_j) \leq M^+[i{-}1, j{-}1] \}
\end{align*}
where $\rho(e_0) = \rho(a_0) = 0$.
\end{definition}

\textbf{Two-zero invariant:} Although closure operates on two index-distinct
nodes $e_0$ and $a_0$, they represent the same constant 0 in concretization.
Closure may mix paths through $e_0$ and $a_0$ precisely because $\gamma(S)$
quantifies only over valuations with $\rho(e_0) = \rho(a_0) = 0$. Rules 9--11
propagate constraints through this shared constant; no explicit $e_0 = a_0$
coupling constraint is needed because concretization enforces it.

\textbf{Intended reading:} $AA[j,0] = L$ means ``for all $\rho \in \gamma(S)$,
$\rho(a_j) \geq L$.'' This makes lower bounds in $AA$ ``guaranteed'' facts
that hold in every concrete execution the abstract state represents.

\begin{definition}[Bottom]
\label{def:bottom}
A state $S$ is \emph{bottom} ($S = \bot$) if $\conc(S) = \emptyset$.
For a \emph{closed} state, this is equivalent to any of:
\begin{itemize}
    \item $\exists i.\; EE[i,i] < 0$ (impossible: $e_i - e_i < 0$)
    \item $\exists j.\; AA[j,j] > 0$ (impossible: $a_j - a_j > 0$)
    \item $\exists i,j.\; M^-[i,j] > M^+[i,j]$ (impossible: lower $>$ upper)
\end{itemize}
For non-closed states, inconsistency may be latent; apply closure first to detect it.
\end{definition}

\begin{definition}[Top]
The \emph{top} state $\top$ has no constraints:
\begin{itemize}
    \item $EE[i,j] = +\infty$ for $i \neq j$, $EE[i,i] = 0$
    \item $AA[i,j] = -\infty$ for $i \neq j$, $AA[i,i] = 0$
    \item $M^+[i,j] = +\infty$, $M^-[i,j] = -\infty$ for all $i,j$
\end{itemize}
Thus $\conc(\top) = \R^{n_E + n_A}$.
\end{definition}

%==============================================================================
\section{Lattice Structure}
\label{sec:lattice}
%==============================================================================

\begin{remark}[Closure as Normalization]
We do not require states to be closed; closure is a normalization that preserves
concretization ($\conc(\text{closure}(S)) = \conc(S)$). Following
Min\'{e}~\cite{mine-thesis}, we keep closure explicit (written $S^*$ when needed)
rather than building it into lattice operations.%
\footnote{Implicit canonicalization after every operation can interact badly with
widening, potentially causing divergence~\cite{mine-thesis}. We apply closure
explicitly when needed for queries or precision, not as an invariant.}
\end{remark}

\subsection{Ordering}

\begin{definition}[Ordering]
\label{def:order}
For states $S_1 = (EE_1, AA_1, M^+_1, M^-_1)$ and $S_2 = (EE_2, AA_2, M^+_2, M^-_2)$:
\[
S_1 \order S_2 \quad\Longleftrightarrow\quad \conc(S_1) \subseteq \conc(S_2)
\]
\end{definition}

\begin{lemma}[Canonical Form]
\label{lem:canonical}
If $S$ is closed and consistent (non-bottom), then for every pair of variables
$(x,y)$ the entries of $S$ coincide with the optimal bounds reachable by
repeated application of Rules 1--11: the infimum for upper bounds, the supremum
for lower bounds. In particular, among all consistent states with the same
concretization, the closed state is the unique entrywise-tightest one.
\end{lemma}

\begin{proof}[Proof sketch]
This is the standard ``shortest/longest path'' property of DBM
closure~\cite{mine-thesis}, generalized to the bipolar setting. At fixpoint,
each entry equals the optimal bound derivable by any sequence of rule
applications. The mixed-interval portion follows the same graph argument with
negation-based reversal edges (\Cref{lem:unary-mixed-saturation}).
\end{proof}

\begin{remark}[Bottom states]
For $\bot$ (where $\conc(\bot) = \emptyset$), we have $\bot \order S$ for all $S$
trivially. The canonical form and syntactic ordering results below apply to
consistent (non-bottom) states.
\end{remark}

\begin{proposition}[Syntactic Ordering]
\label{prop:syn-order}
If the following entrywise conditions hold, then $S_1 \order S_2$:
\begin{enumerate}
    \item $\forall i,j.\; EE_1[i,j] \leq EE_2[i,j]$ (tighter upper bounds)
    \item $\forall i,j.\; AA_1[i,j] \geq AA_2[i,j]$ (tighter lower bounds)
    \item $\forall i,j.\; M^+_1[i,j] \leq M^+_2[i,j]$ (tighter upper bounds)
    \item $\forall i,j.\; M^-_1[i,j] \geq M^-_2[i,j]$ (tighter lower bounds)
\end{enumerate}
The converse holds when both states are closed and consistent (non-bottom).
\end{proposition}

\begin{proof}
\textbf{(Sound direction):} Tighter constraints admit fewer valuations, so
entrywise conditions imply $\conc(S_1) \subseteq \conc(S_2)$.

\textbf{(Converse for closed, consistent states):} By \Cref{lem:canonical},
such states store optimal bounds. If $\conc(S_1) \subseteq \conc(S_2)$, then for each
difference $(x - y)$, the extremal feasible value in $S_1$ cannot exceed that
in $S_2$. Since these extrema are exactly the stored entries, entrywise
comparison follows.
\end{proof}

\subsection{Join (Least Upper Bound)}

\begin{definition}[Join]
\label{def:join}
The \emph{raw join} is defined element-wise:
\[
S_1 \join S_2 = (\max(EE_1, EE_2), \min(AA_1, AA_2),
\max(M^+_1, M^+_2), \min(M^-_1, M^-_2))
\]
For closed states, the \emph{canonical join} applies closure:
$S_1 \join^* S_2 := (S_1 \join S_2)^*$.
\end{definition}

\begin{theorem}[Join Soundness]
\label{thm:join-sound}
$\conc(S_1) \cup \conc(S_2) \subseteq \conc(S_1 \join S_2)$
\end{theorem}

\begin{proof}
Let $\rho \in \conc(S_1)$ (the case $\rho \in \conc(S_2)$ is symmetric).

\textbf{EE constraints} (for $i,j \in [0, n_E]$):
$\rho(e_i) - \rho(e_j) \leq EE_1[i,j] \leq \max(EE_1[i,j], EE_2[i,j])$.

\textbf{AA constraints} (for $i,j \in [0, n_A]$):
$\rho(a_i) - \rho(a_j) \geq AA_1[i,j] \geq \min(AA_1[i,j], AA_2[i,j])$.

\textbf{Mixed constraints} (for $i \in [1, n_E]$, $j \in [1, n_A]$):
\begin{align*}
\rho(e_i) - \rho(a_j) &\leq M^+_1[i{-}1,j{-}1] \leq \max(M^+_1[i{-}1,j{-}1], M^+_2[i{-}1,j{-}1]) \\
\rho(e_i) - \rho(a_j) &\geq M^-_1[i{-}1,j{-}1] \geq \min(M^-_1[i{-}1,j{-}1], M^-_2[i{-}1,j{-}1])
\end{align*}

Thus $\rho$ satisfies all constraints of $S_1 \join S_2$.
\end{proof}

\begin{theorem}[Canonical Join Is Least Upper Bound]
\label{thm:join-lub}
In the poset of closed states ordered by $\order$, the canonical join
$S_1 \join^* S_2$ is the least upper bound of $S_1$ and $S_2$.
\end{theorem}

\begin{proof}
\textbf{Upper bound:} By \Cref{thm:join-sound}, $\conc(S_1) \cup \conc(S_2)
\subseteq \conc(S_1 \join S_2)$. Since closure preserves concretization,
$\conc(S_1 \join^* S_2) = \conc(S_1 \join S_2) \supseteq \conc(S_1) \cup \conc(S_2)$.
Thus $S_1 \order S_1 \join^* S_2$ and $S_2 \order S_1 \join^* S_2$.

\textbf{Least:} Suppose $T$ is closed with $S_1 \order T$ and $S_2 \order T$.
By \Cref{prop:syn-order} (converse for closed states),
$EE_1[i,j] \leq EE_T[i,j]$ and $EE_2[i,j] \leq EE_T[i,j]$, so
$\max(EE_1, EE_2)[i,j] \leq EE_T[i,j]$. Similarly for other matrices.
Thus $S_1 \join S_2 \order T$ by the sound direction of \Cref{prop:syn-order}.
Since closure preserves concretization, $S_1 \join^* S_2 \order T$.
\end{proof}

\begin{remark}[Semantic Significance]
The join semantics reflect the bound polarities:
\begin{itemize}
    \item $EE$, $M^+$ (upper bounds): take $\max$ to weaken upper bounds
    \item $AA$, $M^-$ (lower bounds): take $\min$ to weaken guaranteed lower bounds
\end{itemize}
For the accessible-region example from \Cref{sec:intro}, this means join computes
the \emph{intersection} of guaranteed regions, which is exactly what we need.
\end{remark}

\begin{remark}[Join Is Not Exact]
The inclusion $\conc(S_1) \cup \conc(S_2) \subseteq \conc(S_1 \join S_2)$ is typically
strict ($\subsetneq$), not equality. The join over-approximates the union because it
cannot express disjunctive constraints. For example, if $S_1$ has $e_1 = 3$ and $S_2$
has $e_1 = 5$, the join gives $e_1 \leq 5$, which also admits $e_1 = 4$.
\end{remark}

\subsection{Meet (Greatest Lower Bound)}

\begin{definition}[Meet]
\label{def:meet}
The \emph{raw meet} is defined element-wise:
\[
S_1 \meet S_2 = (\min(EE_1, EE_2), \max(AA_1, AA_2),
\min(M^+_1, M^+_2), \max(M^-_1, M^-_2))
\]
For closed states, the \emph{canonical meet} applies closure:
$S_1 \meet^* S_2 := (S_1 \meet S_2)^*$.
\end{definition}

\begin{theorem}[Meet Correctness]
\label{thm:meet}
$\conc(S_1 \meet S_2) = \conc(S_1) \cap \conc(S_2)$
\end{theorem}

\begin{proof}
A valuation $\rho$ satisfies both $S_1$ and $S_2$ iff it satisfies the
conjunction of all constraints. For upper bounds, $\rho(e_i) - \rho(e_j) \leq c_1
\land \rho(e_i) - \rho(e_j) \leq c_2$ is equivalent to
$\rho(e_i) - \rho(e_j) \leq \min(c_1, c_2)$. Similarly for lower bounds with $\max$.
\end{proof}

\begin{theorem}[Canonical Meet Is Greatest Lower Bound]
\label{thm:meet-glb}
In the poset of closed states ordered by $\order$, the canonical meet
$S_1 \meet^* S_2$ is the greatest lower bound of $S_1$ and $S_2$.
\end{theorem}

\begin{proof}
\textbf{Lower bound:} By \Cref{thm:meet}, $\conc(S_1 \meet S_2) = \conc(S_1)
\cap \conc(S_2) \subseteq \conc(S_1)$ and $\subseteq \conc(S_2)$. Since closure
preserves concretization, $S_1 \meet^* S_2 \order S_1$ and $S_1 \meet^* S_2 \order S_2$.

\textbf{Greatest:} Suppose $T$ is closed with $T \order S_1$ and $T \order S_2$.
Then $\conc(T) \subseteq \conc(S_1) \cap \conc(S_2) = \conc(S_1 \meet S_2)
= \conc(S_1 \meet^* S_2)$, so $T \order S_1 \meet^* S_2$.
\end{proof}

%==============================================================================
\section{Closure}
\label{sec:closure}
%==============================================================================

\begin{definition}[Closure]
\label{def:closure}
The \emph{closure} of a state $S$ is the least fixpoint of Rules 1--11
(\Cref{def:closure-rules}), obtained by repeatedly applying rules until no
entry changes. A state is \emph{closed} if it equals its own closure.
\end{definition}

\begin{remark}[Graph Intuition]
\label{rem:closure-graph}
The closure can be \emph{understood} via a weighted bipolar graph (this is
intuition, not an alternative definition): nodes are
$\{e_0, \ldots, e_{n_E}, a_0, \ldots, a_{n_A}\}$, with edges carrying upper
bounds (difference $\leq c$) or lower bounds (difference $\geq c$).

\textbf{Negation-based reversal:} A lower bound on $(x-y)$ yields an upper
bound on $(y-x)$: $\lower{(x-y)} \geq L$ implies $\upper{(y-x)} \leq -L$.

\textbf{Path composition:} Bounds compose by addition along paths. Cross-polarity
derivations first apply reversal: from $\upper{(x-y)} \leq U$ and
$\lower{(z-y)} \geq L$, we get $\upper{(y-z)} \leq -L$, hence
$\upper{(x-z)} \leq U - L$.

This graph view provides intuition for why Rules 1--11 are sufficient:
Rules 1--8 correspond to relaxing all length-2 paths, after optionally applying
reversal to convert lower bounds to upper bounds (or vice versa). Rules 9--11
handle paths through the shared constant zero.
\end{remark}

\begin{lemma}[Unary--Mixed Saturation]
\label{lem:unary-mixed-saturation}
After closure, unary bounds and mixed bounds are mutually consistent: Rules 9--11
are at fixpoint. That is, no further tightening of unary bounds (in EE, AA) or
mixed bounds (in $M^\pm$) is possible via propagation through the constant 0.
\end{lemma}

\begin{proof}
Rules 9--11 propagate between unary and mixed entries: Rule 9 derives mixed
bounds from unary bounds; Rules 10--11 derive unary bounds from mixed bounds.
At fixpoint, all such derivations are saturated. Since $e_0$ and $a_0$ both
denote 0 in concretization, this ensures the stored bounds correctly reflect
constraints involving the shared constant.
\end{proof}

\subsection{Propagation Rules}

\begin{definition}[Closure Rules]
\label{def:closure-rules}
\textbf{Index conventions:}
\begin{itemize}
    \item $EE$, $AA$: indices in $[0, n_E]$ or $[0, n_A]$, where 0 is the constant zero.
    \item $M^+$, $M^-$: indices in $[0, n_E{-}1] \times [0, n_A{-}1]$.
    \item When rules refer to variables $e_i$, $a_j$ (1-based), mixed matrices use
    $M^\pm[i{-}1, j{-}1]$.
\end{itemize}

\textbf{Sign dictionary} (for deriving reversed-order bounds):
\begin{itemize}
    \item $EE[p,q] = \upper{(e_p - e_q)}$, hence $\lower{(e_q - e_p)} = -EE[p,q]$.
    \item $AA[p,q] = \lower{(a_p - a_q)}$, hence $\upper{(a_q - a_p)} = -AA[p,q]$.
\end{itemize}

The closure applies the following rules until fixpoint:

\textbf{1. Intra-E (Floyd-Warshall, min-plus):}
For all $i,j,k \in [0, n_E]$:
\[
EE[i,j] \leftarrow \min(EE[i,j], EE[i,k] + EE[k,j])
\]

\textbf{2. Intra-A (Floyd-Warshall, max-plus):}
For all $i,j,k \in [0, n_A]$:
\[
AA[i,j] \leftarrow \max(AA[i,j], AA[i,k] + AA[k,j])
\]

\textbf{3. Mixed upper via E:}
For all $i \in [0, n_E{-}1]$, $j \in [0, n_A{-}1]$, $k \in [0, n_E{-}1]$
(here $i,k$ are 0-based indices for variables $e_{i+1}, e_{k+1}$):
\[
M^+[i,j] \leftarrow \min(M^+[i,j], EE[i+1, k+1] + M^+[k,j])
\]

\textbf{4. Mixed upper via A:}
For all $i \in [0, n_E{-}1]$, $j \in [0, n_A{-}1]$, $k \in [0, n_A{-}1]$:
\[
M^+[i,j] \leftarrow \min(M^+[i,j], M^+[i,k] + (-AA[j+1, k+1]))
\]
where $-AA[j+1, k+1] = \upper{(a_{k+1} - a_{j+1})}$.

\textbf{5. Mixed lower via E:}
For all $i \in [0, n_E{-}1]$, $j \in [0, n_A{-}1]$, $k \in [0, n_E{-}1]$:
\[
M^-[i,j] \leftarrow \max(M^-[i,j], (-EE[k+1, i+1]) + M^-[k,j])
\]
where $-EE[k+1, i+1] = \lower{(e_{i+1} - e_{k+1})}$.

\textbf{6. Mixed lower via A:}
For all $i \in [0, n_E{-}1]$, $j \in [0, n_A{-}1]$, $k \in [0, n_A{-}1]$:
\[
M^-[i,j] \leftarrow \max(M^-[i,j], M^-[i,k] + AA[k+1, j+1])
\]

\textbf{7. E via Mixed (E $\to$ A $\to$ E):}
For all $i,j \in [1, n_E]$, $k \in [0, n_A{-}1]$:
\[
EE[i,j] \leftarrow \min(EE[i,j], M^+[i-1, k] + (-M^-[j-1, k]))
\]
This derives $\upper{(e_i - e_j)} \leq \upper{(e_i - a_{k+1})} + \upper{(a_{k+1} - e_j)}$.

\textbf{8. A via Mixed (A $\to$ E $\to$ A):}
For all $i,j \in [1, n_A]$, $k \in [0, n_E{-}1]$:
\[
AA[i,j] \leftarrow \max(AA[i,j], (-M^+[k, i-1]) + M^-[k, j-1])
\]
This derives $\lower{(a_i - a_j)} \geq \lower{(a_i - e_{k+1})} + \lower{(e_{k+1} - a_j)}$.

\textbf{9. Unary-Mixed Propagation:}
For all $i \in [0, n_E{-}1]$, $j \in [0, n_A{-}1]$:

\emph{Semantics:} This derives $\upper{(e_{i+1} - a_{j+1})} \leq \upper{(e_{i+1})} - \lower{(a_{j+1})}$
and $\lower{(e_{i+1} - a_{j+1})} \geq \lower{(e_{i+1})} - \upper{(a_{j+1})}$.
\begin{align*}
M^+[i,j] &\leftarrow \min(M^+[i,j], EE[i+1, 0] - AA[j+1, 0]) \\
M^-[i,j] &\leftarrow \max(M^-[i,j], (-EE[0, i+1]) - (-AA[0, j+1]))
\end{align*}

\textbf{10. Mixed-Unary Propagation (E bounds from Mixed and A):}
For all $i \in [1, n_E]$, $j \in [1, n_A]$:
\begin{align*}
\upper{(e_i)} &\leq \upper{(e_i - a_j)} + \upper{(a_j)}: &
EE[i, 0] &\leftarrow \min(EE[i, 0], M^+[i-1, j-1] + (-AA[0, j])) \\
\lower{(e_i)} &\geq \lower{(e_i - a_j)} + \lower{(a_j)}: &
EE[0, i] &\leftarrow \min(EE[0, i], -(M^-[i-1, j-1] + AA[j, 0]))
\end{align*}

\textbf{11. Mixed-Unary Propagation (A bounds from Mixed and E):}
For all $i \in [1, n_E]$, $j \in [1, n_A]$:
\begin{align*}
\lower{(a_j)} &\geq \lower{(e_i)} - \upper{(e_i - a_j)}: &
AA[j, 0] &\leftarrow \max(AA[j, 0], (-EE[0, i]) - M^+[i-1, j-1]) \\
\upper{(a_j)} &\leq \upper{(e_i)} - \lower{(e_i - a_j)}: &
AA[0, j] &\leftarrow \max(AA[0, j], -(EE[i, 0] - M^-[i-1, j-1]))
\end{align*}
Note: both lines use $\max$ because $AA$ stores \emph{lower} bounds. Recall
$AA[0,j] = \lower{(a_0 - a_j)} = \lower{(-a_j)} = -\upper{(a_j)}$. The second
line derives $\upper{(a_j)} \leq \text{bound}$, equivalently
$-\upper{(a_j)} \geq -\text{bound}$, i.e., $AA[0,j] \geq \text{RHS}$.
\end{definition}

\subsection{Correctness of Closure}

\textbf{Reversal principle:} Throughout these proofs, we use the fact that a
stored lower bound implies a reversed upper bound: if $\lower{(x-y)} \geq L$
then $\upper{(y-x)} \leq -L$. This lets us derive upper bounds from lower-bound
entries and vice versa, even though they are not explicitly stored.

\begin{lemma}[Single-Step Preservation]
\label{lem:closure-step}
Let $S'$ be obtained from $S$ by applying one update of one rule (Rules 1--11)
to one entry. Then $\conc(S') = \conc(S)$.
\end{lemma}

\begin{proof}
Each rule replaces an entry by $\min(\text{old}, \text{candidate})$ for an upper
bound or $\max(\text{old}, \text{candidate})$ for a lower bound. Crucially, the
candidate is a \emph{semantic consequence of $S$}: for every $\rho \in \conc(S)$,
the candidate bound holds. This follows from the triangle inequality
$(x - z) = (x - y) + (y - z)$ applied to entries already in $S$ (with
negation-based reversal for cross-polarity cases). Therefore:
\begin{itemize}
    \item Every $\rho \in \conc(S)$ satisfies the candidate, so $\rho$ satisfies
    the tightened constraint, hence $\conc(S) \subseteq \conc(S')$.
    \item The new constraint is at least as tight as the old, so
    $\conc(S') \subseteq \conc(S)$.
\end{itemize}
We verify that each rule's candidate is a semantic consequence of $S$:

\textbf{Rules 1--2 (Intra-class):} Standard Floyd-Warshall transitivity within
EE (min-plus) and AA (max-plus).

\textbf{Rules 3--4 (Mixed upper):} Derive $\upper{(e_i - a_j)}$ via E or A
intermediates using $\upper{(x-z)} \leq \upper{(x-y)} + \upper{(y-z)}$.

\textbf{Rules 5--6 (Mixed lower):} Derive $\lower{(e_i - a_j)}$ via E or A
intermediates using $\lower{(x-z)} \geq \lower{(x-y)} + \lower{(y-z)}$.

\textbf{Rules 9--11 (Unary):} Specialize the above to/from the constant 0.

\textbf{Rules 7--8 (Cross-polarity):} These mix upper and lower bounds via
negation-based reversal. For Rule 7, with $\rho \in \conc(S)$, $i,j \in [1, n_E]$,
$k \in [0, n_A{-}1]$ (intermediate $a_{k+1}$):
\begin{align*}
\rho(e_i) - \rho(e_j) &= (\rho(e_i) - \rho(a_{k+1})) + (\rho(a_{k+1}) - \rho(e_j)) \\
&\leq M^+[i-1, k] + (-M^-[j-1, k])
\end{align*}
using $\rho(e_i) - \rho(a_{k+1}) \leq M^+[i-1, k]$ and
$\rho(a_{k+1}) - \rho(e_j) \leq -M^-[j-1, k]$ (from
$\rho(e_j) - \rho(a_{k+1}) \geq M^-[j-1, k]$). Rule 8 is symmetric.
\end{proof}

\begin{theorem}[Closure Preserves Concretization]
\label{thm:closure-sound}
For any state $S$, $\conc(\text{closure}(S)) = \conc(S)$.
\end{theorem}

\begin{proof}
Closure is a sequence of single-step rule applications. By
\Cref{lem:closure-step}, each step preserves $\conc$. Hence the entire
iteration preserves $\conc$, and equality holds at fixpoint.
\end{proof}

\begin{remark}[Closure Complexity]
\label{rem:closure-complexity}
The fixpoint of Rules 1--11 can be computed in $O(n^3)$ time, where
$n = n_E + n_A + 2$, by adapting Floyd-Warshall. The closure reduces to
shortest paths (for upper bounds) and longest paths (for lower bounds) on a
signed graph with $n$ nodes. See \cite{mine-thesis} for the general
DBM-to-shortest-paths reduction.
\end{remark}

\begin{remark}[Implementation]
The reference implementation uses iterative fixpoint computation (apply rules
until no change) rather than the structured Floyd-Warshall order. Since the
rule-application operator is monotone in the product lattice order, iteration
to stability yields the least fixpoint of Rules 1--11, which coincides with
the path-closure semantics in exact arithmetic. Complexity may differ from the
$O(n^3)$ Floyd-Warshall bound. With finite-precision arithmetic (floats),
termination is guaranteed because each entry changes monotonically and has
finitely many representable values. See \Cref{sec:impl}.
\end{remark}

\begin{remark}[Bottom Detection]
Closure can create inconsistency (e.g., Rule 2 may push $AA[j,j]$ above 0 via
a positive cycle of lower bounds). After closure, check the bottom conditions
from \Cref{def:bottom}: if $EE[i,i] < 0$, $AA[j,j] > 0$, or $M^-[i,j] > M^+[i,j]$
for any indices, return $\bot$.
\end{remark}

%==============================================================================
\section{Worked Examples}
\label{sec:examples}
%==============================================================================

\subsection{Example 1: Accessible Region Intersection}

Consider the motivating example from \Cref{sec:intro}: tracking guaranteed
accessible offsets around a pointer $p$. We represent the guaranteed accessible
interval $[p - \ell, p + r]$ by non-negative distances $\ell$ (left reach) and
$r$ (right reach).

We use $n_E = 0$ (no may-variables) and $n_A = 2$ ($a_1 = \text{left\_reach}$,
$a_2 = \text{right\_reach}$). We track \emph{guaranteed} reach, so all
constraints are lower bounds ($\geq$).

\textbf{Branch 1:} Accessible offsets $[p+0, p+1]$ means left\_reach $\geq 0$,
right\_reach $\geq 1$.
\[
AA_1 = \begin{pmatrix} 0 & -\infty & -\infty \\ 0 & 0 & -\infty \\ 1 & -\infty & 0 \end{pmatrix}
\]
(Reading: $AA[1,0] = 0$ means $a_1 \geq 0$; $AA[2,0] = 1$ means $a_2 \geq 1$.)

\textbf{Branch 2:} Accessible offsets $[p-1, p+0]$ means left\_reach $\geq 1$,
right\_reach $\geq 0$.
\[
AA_2 = \begin{pmatrix} 0 & -\infty & -\infty \\ 1 & 0 & -\infty \\ 0 & -\infty & 0 \end{pmatrix}
\]

\textbf{Join} (element-wise $\min$ for AA):
\[
AA = \min(AA_1, AA_2) = \begin{pmatrix} 0 & -\infty & -\infty \\ 0 & 0 & -\infty \\ 0 & -\infty & 0 \end{pmatrix}
\]

Result: $a_1 \geq 0$ (left\_reach), $a_2 \geq 0$ (right\_reach). The guaranteed
accessible region after join is $[0, 0]$---only the pointer position itself.
This is the \emph{intersection} of the two branch guarantees, computed
automatically by the join semantics.

\subsection{Example 2: Array Bounds (Safety Check)}

With $n_E = 1$ (index) and $n_A = 1$ (size):

\textbf{Branch 1:} index $= 5$, size $\geq 10$. \quad
\textbf{Branch 2:} index $= 3$, size $\geq 7$.

\textbf{After join:}
\begin{itemize}
    \item $EE = \max$: index $\leq \max(5, 3) = 5$
    \item $AA = \min$: size $\geq \min(10, 7) = 7$
\end{itemize}

\textbf{Safety check:} $\upper{(\text{index})} = 5 < 7 = \lower{(\text{size})}$. Safe!

Note: This particular check can also be done with standard DBM; the example
demonstrates the mechanics, not a unique capability.

\subsection{Example 3: E $\to$ A $\to$ E Propagation}

Let $n_E = 2$, $n_A = 1$. Given:
\begin{itemize}
    \item $e_1 - a_1 \leq 2$ (set $M^+[0,0] = 2$)
    \item $a_1 - e_2 \leq 3$, equivalently $e_2 - a_1 \geq -3$ (set $M^-[1,0] = -3$)
\end{itemize}

\textbf{Propagation (Rule 7):}
\begin{align*}
\upper{(e_1 - e_2)} &\leq \upper{(e_1 - a_1)} + \upper{(a_1 - e_2)} \\
&= M^+[0,0] + (-M^-[1,0]) \\
&= 2 + (-(-3)) = 2 + 3 = 5
\end{align*}

Thus closure derives $EE[1,2] \leq 5$, i.e., $e_1 - e_2 \leq 5$.

\subsection{Example 4: A $\to$ E $\to$ A Propagation}

Let $n_E = 1$, $n_A = 2$. Given:
\begin{itemize}
    \item $a_1 \geq 5$ (set $AA[1,0] = 5$)
    \item $e_1 - a_1 = -2$ (exact: $M^+[0,0] = M^-[0,0] = -2$)
\end{itemize}

\textbf{Propagation (Rule 10, Mixed-Unary):}
\begin{align*}
\lower{(e_1)} &\geq \lower{(e_1 - a_1)} + \lower{(a_1)} \\
&= M^-[0,0] + AA[1,0] \\
&= -2 + 5 = 3
\end{align*}

Thus closure derives $-EE[0,1] \geq 3$, i.e., $EE[0,1] \leq -3$, meaning $e_1 \geq 3$.

%==============================================================================
\section{Abstract Transformers}
\label{sec:transformers}
%==============================================================================

\subsection{Assignment to E Variable}

For $e_i := [L, U]$ (non-deterministic assignment to interval):

\begin{enumerate}
    \item \textbf{Forget:} Set $EE[i, j] = EE[j, i] = +\infty$ for all $j \neq i$,
    and $M^+[i-1, \cdot] = +\infty$, $M^-[i-1, \cdot] = -\infty$.
    (Keep $EE[i,i] = 0$ unchanged.)

    \item \textbf{Set bounds:} $EE[i, 0] = U$ (upper), $EE[0, i] = -L$ (lower).

    \item \textbf{Close:} Apply closure to propagate new constraints.
\end{enumerate}

\subsection{Assignment to A Variable}

For $a_j := [L, U]$:

\begin{enumerate}
    \item \textbf{Forget:} Set $AA[j, k] = AA[k, j] = -\infty$ for all $k \neq j$,
    and $M^+[\cdot, j-1] = +\infty$, $M^-[\cdot, j-1] = -\infty$.
    (Keep $AA[j,j] = 0$ unchanged.)

    \item \textbf{Set bounds:} $AA[j, 0] = L$ (lower), $AA[0, j] = -U$ (upper).

    \item \textbf{Close.}
\end{enumerate}

\subsection{Guards}

For a guard $e_i - a_j \leq c$:
\[
M^+[i-1, j-1] \leftarrow \min(M^+[i-1, j-1], c)
\]
Then close.

For a guard $e_i - a_j \geq c$:
\[
M^-[i-1, j-1] \leftarrow \max(M^-[i-1, j-1], c)
\]
Then close.

\subsection{Safety Query}

\begin{definition}[Safe Access Query]
The query $\texttt{check\_safe\_access}(S, i, j)$ returns true iff
$0 \leq e_i < a_j$ holds for all $\rho \in \conc(S)$:
\[
\texttt{check\_safe\_access}(S, i, j) =
\big(\lower{(e_i)} \geq 0\big) \land \big(\upper{(e_i)} < \lower{(a_j)}\big)
\]
where:
\begin{align*}
\lower{(e_i)} &= -EE[0, i] \\
\upper{(e_i)} &= EE[i, 0] \\
\lower{(a_j)} &= AA[j, 0]
\end{align*}
The strict inequality $\upper{(e_i)} < \lower{(a_j)}$ is checked directly on
the bounds. For integer variables, this is equivalent to
$\upper{(e_i)} - \lower{(a_j)} \leq -1$.
\end{definition}

%==============================================================================
\section{Comparison with Standard DBM}
\label{sec:comparison}
%==============================================================================

\subsection{What Standard DBM Can Do}

Standard DBM \emph{can} represent lower bounds: the constraint $x \geq L$ is
encoded as $0 - x \leq -L$. After a join, lower bounds are preserved correctly
(the join takes $\max$ on upper bounds of $0-x$, which corresponds to $\min$
on lower bounds of $x$). So for simple array bounds checking with explicit
size variables, standard DBM suffices.

\subsection{What May-Must DBM Provides}

The value of May-Must DBM is not that it can express facts standard DBM cannot,
but rather:

\begin{enumerate}
    \item \textbf{Explicit polarity}: Variables are classified by which bound
    direction matters. This makes the analysis design clearer and avoids
    tracking bounds that are irrelevant to the verification goal.

    \item \textbf{Natural intersection semantics}: For ``guaranteed reach''
    properties (as in \Cref{sec:intro}), the join on A-variables directly
    computes the intersection. With standard DBM, you would encode left/right
    reach as two variables and get the same result, but the may-must framing
    makes the intent explicit.

    \item \textbf{Structured cross-class propagation}: The interval constraints
    $M^+$ and $M^-$ on E--A differences enable systematic E$\to$A$\to$E and
    A$\to$E$\to$A propagation. In standard DBM with all variables in one pool,
    similar propagation occurs, but the polarity-aware structure here makes it
    easier to reason about which bounds tighten which.
\end{enumerate}

\begin{table}[h]
\centering
\begin{tabular}{lcc}
\toprule
\textbf{Aspect} & \textbf{Standard DBM} & \textbf{May-Must DBM} \\
\midrule
Lower bounds & Encoded as $0-x \leq -L$ & Direct in AA \\
Polarity & Implicit & Explicit (E vs A) \\
Cross-class constraints & All pairs uniformly & Interval on E--A \\
Join semantics & $\max$ on all entries & $\max$ on E, $\min$ on A \\
\bottomrule
\end{tabular}
\caption{Structural comparison (not a precision claim)}
\label{tab:comparison}
\end{table}

\textbf{Summary}: May-Must DBM is a \emph{design choice} that makes polarity
explicit, not a strict precision improvement over standard DBM. Its value is
in clarity of intent and structured propagation for analyses where some
variables represent ``could be'' bounds and others represent ``guaranteed''
bounds.

%==============================================================================
\section{Limitations}
\label{sec:limitations}
%==============================================================================

\begin{enumerate}
    \item \textbf{Fixed variable classification:} Variables must be assigned to
    E or A at analysis design time. A variable cannot simultaneously be treated
    as ``may'' and ``must'' in this factoring; if you need both tight upper
    \emph{and} tight guaranteed-lower information about the same quantity, you
    must model it using two related variables or keep it in the unified DBM
    pool. This requires knowing at analysis design time which bound direction
    matters for each variable.

    \item \textbf{No strict inequalities (real-valued):} The domain tracks
    $\leq$ and $\geq$, not $<$ and $>$, when variables range over reals.
    For \emph{integer} variables, strict inequalities are encoded via:
    $x < y \Longleftrightarrow x - y \leq -1$ and
    $x > y \Longleftrightarrow x - y \geq 1$.
    This encoding is sound only for integers.

    \item \textbf{Linear constraints only:} Like standard DBM, only difference
    constraints ($x - y \leq c$) are expressible, not general linear constraints
    ($ax + by \leq c$ for $a, b \neq \pm 1$). The Octagon domain extends DBM to
    constraints of the form $\pm x \pm y \leq c$, but combining octagons with
    may-must approximation is future work.

    \item \textbf{Widening loses precision:} Standard widening on upper bounds
    may go to $+\infty$ quickly, losing relational information. For loops where
    index bounds depend on must-approximated sizes, more sophisticated widening
    strategies (e.g., threshold-based widening) or narrowing phases may be needed.

    \item \textbf{Join loses disjunctive information:} As noted in
    \Cref{sec:lattice}, the join cannot express disjunctions. After joining
    branches where $e_1 = 3$ and $e_1 = 5$, the domain only knows $e_1 \leq 5$,
    losing the fact that $e_1 \in \{3, 5\}$.
\end{enumerate}

%==============================================================================
\section{Conclusion}
\label{sec:conclusion}
%==============================================================================

The May-Must DBM domain provides a polarity-aware design for relational
numerical analysis. While expressively equivalent to standard DBM (which can
also represent lower bounds via negation), the may-must structure offers
several practical advantages:

\begin{itemize}
    \item \textbf{Explicit intent}: Variables are classified by which bound
    direction matters, making the analysis design self-documenting.

    \item \textbf{Pitfall prevention}: The common mistake of tracking
    ``guaranteed regions'' with scalar summaries that lose precision at joins
    is structurally avoided.

    \item \textbf{Natural intersection semantics}: For must-variables
    representing guaranteed properties (like accessible memory regions), the
    join automatically computes the intersection of guarantees.
\end{itemize}

The domain is particularly suited for verification tasks mixing ``possible
value'' bounds (indices, offsets) with ``guaranteed minimum'' bounds (sizes,
capacities, reaches). The polarity-aware design makes it harder to accidentally
compute the wrong join for guarantee-style facts.

\appendix

%==============================================================================
\section{Implementation Notes}
\label{sec:impl}
%==============================================================================

The reference implementation is available in \texttt{mmdbm/maymust\_dbm.py}.
Key implementation choices:

\begin{itemize}
    \item Matrices are represented as NumPy arrays with \texttt{dtype=float}.
    \item $+\infty$ and $-\infty$ are represented as \texttt{float('inf')} and
    \texttt{float('-inf')}.
    \item Closure iterates until no matrix entry changes, with a safety bound
    to prevent non-termination.
    \item States are immutable (frozen dataclass) to prevent accidental mutation.
\end{itemize}

\end{document}
